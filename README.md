# NPC Onchain Data Ingestion Platform

A comprehensive enterprise-grade platform for aggregating, analyzing, and deriving insights from blockchain data across multiple protocols, chains, and data sources.

```mermaid
graph TB
subgraph Data Sources
DL[DeFi Llama]
DA[Dune Analytics]
BQ[Bitquery]
HL[Hyperliquid]
TG[The Graph]
FA[Footprint Analytics]
end
subgraph Ingestion Layer
WS[WebSocket Service]
DI[Data Ingestion Service]
RL[Rate Limiter]
end
subgraph Processing Layer
VP[Validation Pipeline]
NP[Normalization Pipeline]
QS[Quality Scoring]
AD[Anomaly Detection]
end
subgraph Storage Layer
RC[Redis Cache]
TS[Time Series DB]
SB[Supabase]
end
subgraph Analytics Engine
MA[Market Analysis]
FA2[Funding Arbitrage]
LM[Liquidity Monitoring]
VM[Volume Metrics]
end
subgraph API Layer
REST[REST API]
WS2[WebSocket API]
GQL[GraphQL API]
end
%% Data flow connections
DL & DA & BQ & HL & TG & FA --> WS & DI
WS & DI --> RL
RL --> VP
VP --> NP
NP --> QS
QS --> AD
AD --> RC
RC --> TS
TS --> SB
SB --> MA & FA2 & LM & VM
MA & FA2 & LM & VM --> REST & WS2 & GQL
%% Styling
classDef source fill:#f9f,stroke:#333,stroke-width:2px
classDef service fill:#bbf,stroke:#333,stroke-width:2px
classDef storage fill:#bfb,stroke:#333,stroke-width:2px
classDef analytics fill:#ffb,stroke:#333,stroke-width:2px
classDef api fill:#fbb,stroke:#333,stroke-width:2px
class DL,DA,BQ,HL,TG,FA source
class WS,DI,RL,VP,NP,QS,AD service
class RC,TS,SB storage
class MA,FA2,LM,VM analytics
class REST,WS2,GQL api
```

## Features

### Data Collection & Processing
- **Multi-Source Integration**
  - DeFi Llama: Protocol TVL and metrics
  - Dune Analytics: On-chain analytics
  - Bitquery: Cross-chain data
  - Hyperliquid: Perpetual markets
  - The Graph: Protocol-specific metrics
  - Footprint Analytics: NFT and GameFi data

- **Real-Time Processing**
  - WebSocket streaming for market data
  - Redis-based caching layer
  - Efficient data normalization pipeline

### Analytics & Insights
- **Market Analysis**
  - Funding rate arbitrage detection
  - Liquidity imbalance monitoring
  - Cross-exchange opportunities
  - Volume profile analysis

- **Data Quality**
  - Automated validation pipelines
  - Cross-source verification
  - Anomaly detection
  - Data completeness scoring

### Infrastructure
- **Storage & Database**
  - Supabase for structured data
  - Time-series optimized tables
  - Efficient indexing strategies
  - Version-controlled schemas

- **Performance**
  - High-throughput ingestion
  - Sub-second query response
  - Horizontal scalability
  - Automated failover

## ğŸš€ Quick Start

```bash
# Install dependencies
yarn install

# Set up environment variables
cp .env.example .env

# Run development server
yarn dev

# Start data ingestion
yarn ingest

# Run tests
yarn test
```

## ğŸ“Š Data Models

### Core Metrics
```typescript
interface TokenMetrics {
  price: number;
  volume_24h: number;
  market_cap: number;
  holder_count: number;
  // ... more fields
}

interface PerpetualMetrics {
  funding_rate: number;
  open_interest: number;
  volume_24h: number;
  long_positions: number;
  // ... more fields
}
```

## ğŸ”§ Configuration

### Environment Variables
```env
# API Keys
DEFILLAMA_API_KEY=your_key
DUNE_API_KEY=your_key
BITQUERY_API_KEY=your_key

# Database
SUPABASE_URL=your_url
SUPABASE_KEY=your_key

# Cache
REDIS_URL=your_url
```

## ğŸ“ˆ Usage Examples

### Token Analytics
```typescript
import { BlockchainAnalyticsService } from 'blockchain-analytics';

const analytics = new BlockchainAnalyticsService({
  supabaseUrl: process.env.SUPABASE_URL,
  supabaseKey: process.env.SUPABASE_KEY
});

// Fetch token metrics
const metrics = await analytics.ingestTokenMetrics({
  symbol: 'ETH',
  chain: 'ethereum'
});
```

### Real-Time Data Streaming
```typescript
import { WebSocketService } from 'blockchain-analytics';

const ws = new WebSocketService(cache);

ws.on('data', ({ provider, data }) => {
  console.log(`New data from ${provider}:`, data);
});

await ws.connect(DataProvider.HYPERLIQUID);
```

## ğŸ—ï¸ Architecture

### Data Flow
1. Multi-source data ingestion
2. Real-time processing & validation
3. Quality scoring & normalization
4. Storage & indexing
5. API exposure & streaming

### Components
- Data Ingestion Services
- WebSocket Streaming
- Redis Cache Layer
- Supabase Database
- Analytics Engine
- API Layer

## ğŸ§ª Testing

```bash
# Run unit tests
yarn test

# Run integration tests
yarn test:integration

# Test data ingestion
yarn test-ingest
```

## ğŸ“š Documentation

- [API Reference](./docs/API.md)
- [Schema Documentation](./docs/SCHEMA.md)
- [Development Guide](./docs/DEVELOPMENT.md)
- [Deployment Guide](./docs/DEPLOYMENT.md)

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch
3. Run tests and linting
4. Submit a pull request

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details

## ğŸ”— Related Projects

- [Trading Strategies](https://github.com/yourusername/trading-strategies)
- [Market Making Bot](https://github.com/yourusername/market-maker)
- [Analytics Dashboard](https://github.com/yourusername/analytics-dashboard)

## ğŸ“Š Performance Metrics

- Data freshness: < 1 second
- Query response time: < 100ms
- Data accuracy: > 99.9%
- System uptime: > 99.99%

## ğŸŒŸ Roadmap

- [ ] Machine Learning Models
- [ ] Advanced Analytics Dashboard
- [ ] Cross-Chain Arbitrage
- [ ] Automated Trading Strategies
