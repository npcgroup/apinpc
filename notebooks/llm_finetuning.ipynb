{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJGlmBQSzERq"
      },
      "source": [
        "# LLM Finetuning on Crypto Datasets\n",
        "\n",
        "In this notebook, we will finetune a Qwen-2.5-7b-instruct model using AutoTrain Advanced.\n",
        "You can replace the model with any Hugging Face transformers compatible model and dataset with any other dataset in proper formatting.\n",
        "For dataset formatting, please take a look at [docs](https://huggingface.co/docs/autotrain/index)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "0rGgSHzAzERr",
        "outputId": "4a7f9470-b3d2-48b8-86f4-150e65433825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
            "               [--paths] [--json] [--debug]\n",
            "               [subcommand]\n",
            "\n",
            "Jupyter: Interactive Computing\n",
            "\n",
            "positional arguments:\n",
            "  subcommand     the subcommand to launch\n",
            "\n",
            "options:\n",
            "  -h, --help     show this help message and exit\n",
            "  --version      show the versions of core jupyter packages and exit\n",
            "  --config-dir   show Jupyter config dir\n",
            "  --data-dir     show Jupyter data dir\n",
            "  --runtime-dir  show Jupyter runtime dir\n",
            "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
            "                 format.\n",
            "  --json         output paths as machine-readable json\n",
            "  --debug        output debug information about paths\n",
            "\n",
            "Available subcommands: kernel kernelspec migrate run troubleshoot\n",
            "\n",
            "Jupyter command `jupyter-nbextension` not found.\n"
          ]
        }
      ],
      "source": [
        "from autotrain.params import LLMTrainingParams\n",
        "from autotrain.project import AutoTrainProject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "diBQ_u03zERr"
      },
      "outputs": [],
      "source": [
        "HF_USERNAME = \"Episte\"\n",
        "HF_TOKEN = \"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\" # get it from https://huggingface.co/settings/token\n",
        "# It is recommended to use secrets or environment variables to store your HF_TOKEN\n",
        "# your token is required if push_to_hub is set to True or if you are accessing a gated model/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "dcqeO6DHzERs"
      },
      "outputs": [],
      "source": [
        "params = LLMTrainingParams(\n",
        "    model=\"Qwen/Qwen2.5-7B-Instruct\",\n",
        "    project_name=\"autotrainqwen\",\n",
        "    data_path=\"cogneolabs/Cogneo-Crypto-Sentiment\",\n",
        "    train_split=\"train\",\n",
        "    text_column=\"description\",  # Changed from 'text' to 'description'\n",
        "    trainer=\"default\",\n",
        "    epochs=1,\n",
        "    batch_size=2,\n",
        "    lr=3e-5,\n",
        "    warmup_ratio=0.1,\n",
        "    gradient_accumulation=4,\n",
        "    optimizer=\"adamw_torch\",\n",
        "    scheduler=\"linear\",\n",
        "    weight_decay=0.0,\n",
        "    max_grad_norm=1.0,\n",
        "    seed=42,\n",
        "    quantization=\"int4\",\n",
        "    target_modules=\"all-linear\",\n",
        "    block_size=1024,\n",
        "    model_max_length=2048,\n",
        "    padding=\"right\",\n",
        "    add_eos_token=True,\n",
        "    # Optional: if you want to combine columns, you can process them beforehand\n",
        "    # text_column=\"description,title\",  # This would combine both columns\n",
        "    log=\"none\",\n",
        "    peft=False,  # Set to False as in the current config\n",
        "    merge_adapter=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go0icAulzERs"
      },
      "source": [
        "If your dataset is in CSV / JSONL format (JSONL is most preferred) and is stored locally, make the following changes to `params`:\n",
        "\n",
        "```python\n",
        "params = LLMTrainingParams(\n",
        "    data_path=\"/Users/shaanp/projects/testing/0000.csv\", # this is the path to folder where train.jsonl/train.csv is located\n",
        "    text_column=\"text\", # this is the column name in the CSV/JSONL file which contains the text\n",
        "    train_split = \"0000\" # this is the filename without extension\n",
        "    .\n",
        "    .\n",
        "    .\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4aOpGdA6zERs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-02-06 17:42:46\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-02-06 17:42:46\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m514\u001b[0m - \u001b[1m['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'bf16', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrain-llama32-1b-finetune/training_params.json', '--mixed_precision', 'bf16', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrain-llama32-1b-finetune/training_params.json', '--mixed_precision', 'bf16', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-02-06 17:42:46\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m515\u001b[0m - \u001b[1m{'model': 'Qwen/Qwen2.5-7B-Instruct', 'project_name': 'autotrainqwen', 'data_path': 'cogneolabs/Cogneo-Crypto-Sentiment', 'train_split': 'train', 'valid_split': None, 'add_eos_token': True, 'block_size': 1024, 'model_max_length': 2048, 'padding': 'right', 'trainer': 'default', 'use_flash_attention_2': False, 'log': 'none', 'disable_gradient_checkpointing': False, 'logging_steps': -1, 'eval_strategy': 'epoch', 'save_total_limit': 1, 'auto_find_batch_size': False, 'mixed_precision': None, 'lr': 3e-05, 'epochs': 1, 'batch_size': 2, 'warmup_ratio': 0.1, 'gradient_accumulation': 4, 'optimizer': 'adamw_torch', 'scheduler': 'linear', 'weight_decay': 0.0, 'max_grad_norm': 1.0, 'seed': 42, 'chat_template': None, 'quantization': 'int4', 'target_modules': 'all-linear', 'merge_adapter': False, 'peft': False, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.05, 'model_ref': None, 'dpo_beta': 0.1, 'max_prompt_length': 128, 'max_completion_length': None, 'prompt_text_column': None, 'text_column': 'description', 'rejected_text_column': None, 'push_to_hub': False, 'username': None, 'token': None, 'unsloth': False, 'distributed_backend': None}\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/Users/shaanp/projects/testing/venv/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/Users/shaanp/projects/testing/venv/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/Users/shaanp/projects/testing/venv/lib/python3.12/site-packages/accelerate/commands/launch.py\", line 1146, in launch_command\n",
            "    args, defaults, mp_from_config_flag = _validate_launch_command(args)\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/shaanp/projects/testing/venv/lib/python3.12/site-packages/accelerate/commands/launch.py\", line 1066, in _validate_launch_command\n",
            "    raise ValueError(\"bf16 mixed precision requires PyTorch >= 1.10 and a supported device.\")\n",
            "ValueError: bf16 mixed precision requires PyTorch >= 1.10 and a supported device.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "42095"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# this will train the model locally\n",
        "project = AutoTrainProject(\n",
        "    params=params,\n",
        "    backend=\"local\",\n",
        "    process=True\n",
        ")\n",
        "project.create()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
