{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJGlmBQSzERq"
      },
      "source": [
        "# LLM Finetuning using AutoTrain\n",
        "\n",
        "In this notebook, we will finetune a Qwen/Qwen2.5-7b-instruct model using AutoTrain Advanced.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "import os\n",
        "os.environ['HF_ACCESS_TOKEN'] = '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'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pwb_toolbox.datasets as pwb_ds\n",
        "\n",
        "# Load a dataset, for example, \"Stocks-Daily-Price\"\n",
        "df = pwb_ds.load_dataset(\"Cryptocurrencies-Daily-Price\")\n",
        "\n",
        "# Your dataset is now ready to use!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAVE</td>\n",
              "      <td>2024-02-26</td>\n",
              "      <td>100.330000</td>\n",
              "      <td>103.930000</td>\n",
              "      <td>97.890000</td>\n",
              "      <td>102.780000</td>\n",
              "      <td>7.225922e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAVE</td>\n",
              "      <td>2024-02-27</td>\n",
              "      <td>102.940000</td>\n",
              "      <td>105.820000</td>\n",
              "      <td>101.050000</td>\n",
              "      <td>104.800000</td>\n",
              "      <td>6.284598e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAVE</td>\n",
              "      <td>2024-02-28</td>\n",
              "      <td>104.920000</td>\n",
              "      <td>108.730000</td>\n",
              "      <td>97.870000</td>\n",
              "      <td>104.490000</td>\n",
              "      <td>7.446371e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAVE</td>\n",
              "      <td>2024-02-29</td>\n",
              "      <td>104.430000</td>\n",
              "      <td>114.960000</td>\n",
              "      <td>103.160000</td>\n",
              "      <td>105.850000</td>\n",
              "      <td>8.382286e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAVE</td>\n",
              "      <td>2024-03-01</td>\n",
              "      <td>105.850000</td>\n",
              "      <td>110.690000</td>\n",
              "      <td>105.830000</td>\n",
              "      <td>110.620000</td>\n",
              "      <td>3.172164e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29604</th>\n",
              "      <td>ZRX</td>\n",
              "      <td>2025-02-05</td>\n",
              "      <td>0.322564</td>\n",
              "      <td>0.326608</td>\n",
              "      <td>0.304277</td>\n",
              "      <td>0.309000</td>\n",
              "      <td>8.450443e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29605</th>\n",
              "      <td>ZRX</td>\n",
              "      <td>2025-02-06</td>\n",
              "      <td>0.309341</td>\n",
              "      <td>0.317677</td>\n",
              "      <td>0.287485</td>\n",
              "      <td>0.291695</td>\n",
              "      <td>1.555549e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29606</th>\n",
              "      <td>ZRX</td>\n",
              "      <td>2025-02-07</td>\n",
              "      <td>0.291533</td>\n",
              "      <td>0.314455</td>\n",
              "      <td>0.285354</td>\n",
              "      <td>0.294516</td>\n",
              "      <td>1.401990e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29607</th>\n",
              "      <td>ZRX</td>\n",
              "      <td>2025-02-08</td>\n",
              "      <td>0.294000</td>\n",
              "      <td>0.314000</td>\n",
              "      <td>0.292274</td>\n",
              "      <td>0.313982</td>\n",
              "      <td>8.660158e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29608</th>\n",
              "      <td>ZRX</td>\n",
              "      <td>2025-02-09</td>\n",
              "      <td>0.313982</td>\n",
              "      <td>0.315657</td>\n",
              "      <td>0.310569</td>\n",
              "      <td>0.314000</td>\n",
              "      <td>4.055252e+04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29609 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      symbol       date        open        high         low       close  \\\n",
              "0       AAVE 2024-02-26  100.330000  103.930000   97.890000  102.780000   \n",
              "1       AAVE 2024-02-27  102.940000  105.820000  101.050000  104.800000   \n",
              "2       AAVE 2024-02-28  104.920000  108.730000   97.870000  104.490000   \n",
              "3       AAVE 2024-02-29  104.430000  114.960000  103.160000  105.850000   \n",
              "4       AAVE 2024-03-01  105.850000  110.690000  105.830000  110.620000   \n",
              "...      ...        ...         ...         ...         ...         ...   \n",
              "29604    ZRX 2025-02-05    0.322564    0.326608    0.304277    0.309000   \n",
              "29605    ZRX 2025-02-06    0.309341    0.317677    0.287485    0.291695   \n",
              "29606    ZRX 2025-02-07    0.291533    0.314455    0.285354    0.294516   \n",
              "29607    ZRX 2025-02-08    0.294000    0.314000    0.292274    0.313982   \n",
              "29608    ZRX 2025-02-09    0.313982    0.315657    0.310569    0.314000   \n",
              "\n",
              "             volume  \n",
              "0      7.225922e+04  \n",
              "1      6.284598e+04  \n",
              "2      7.446371e+04  \n",
              "3      8.382286e+04  \n",
              "4      3.172164e+04  \n",
              "...             ...  \n",
              "29604  8.450443e+05  \n",
              "29605  1.555549e+06  \n",
              "29606  1.401990e+06  \n",
              "29607  8.660158e+05  \n",
              "29608  4.055252e+04  \n",
              "\n",
              "[29609 rows x 7 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 100%|██████████| 87599/87599 [00:00<00:00, 1422453.28 examples/s]\n",
            "Generating validation split: 100%|██████████| 10570/10570 [00:00<00:00, 2333357.54 examples/s]\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset('squad')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "DatasetNotFoundError",
          "evalue": "Dataset 'paperswithbacktest/Cryptocurrencies-Daily-Price' is a gated dataset on the Hub. You must be authenticated to access it.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset_crypto \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpaperswithbacktest/Cryptocurrencies-Daily-Price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/GitHub/apinpc/venv/lib/python3.13/site-packages/datasets/load.py:2129\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2124\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[1;32m   2125\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2126\u001b[0m )\n\u001b[1;32m   2128\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2129\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2143\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2146\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
            "File \u001b[0;32m~/Documents/GitHub/apinpc/venv/lib/python3.13/site-packages/datasets/load.py:1849\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   1847\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1848\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 1849\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
            "File \u001b[0;32m~/Documents/GitHub/apinpc/venv/lib/python3.13/site-packages/datasets/load.py:1719\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt reach the Hugging Face Hub for dataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, (DataFilesNotFoundError, DatasetNotFoundError, EmptyDatasetError)):\n\u001b[0;32m-> 1719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m):\n\u001b[1;32m   1721\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trust_remote_code:\n",
            "File \u001b[0;32m~/Documents/GitHub/apinpc/venv/lib/python3.13/site-packages/datasets/load.py:1703\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1701\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m   1702\u001b[0m         message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Visit the dataset page at https://huggingface.co/datasets/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to ask for access.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(\n\u001b[1;32m   1706\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRevision \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist for dataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1707\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[0;31mDatasetNotFoundError\u001b[0m: Dataset 'paperswithbacktest/Cryptocurrencies-Daily-Price' is a gated dataset on the Hub. You must be authenticated to access it."
          ]
        }
      ],
      "source": [
        "dataset_crypto = load_dataset('paperswithbacktest/Cryptocurrencies-Daily-Price')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 87599\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 10570\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>**user report** :--:--:--:-- **total submissio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>purchase but no positions? dont lie, you paper...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>post the fucking million with today’s date the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>congratulations! and fuck you!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>now use that money to make a time machine to b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  **user report** :--:--:--:-- **total submissio...\n",
              "1  purchase but no positions? dont lie, you paper...\n",
              "2  post the fucking million with today’s date the...\n",
              "3                     congratulations! and fuck you!\n",
              "4  now use that money to make a time machine to b..."
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert = pd.read_parquet('/Users/shaanp/projects/testing/datasets/cryptobert-dataset.parquet')\n",
        "bert.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>**user report** :--:--:--:-- **total submissio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>purchase but no positions? dont lie, you paper...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>post the fucking million with today’s date the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>congratulations! and fuck you!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>now use that money to make a time machine to b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3206198</th>\n",
              "      <td>when is coinbase giving us our flare drops? it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3206199</th>\n",
              "      <td>what is time for open and close on a chart? it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3206200</th>\n",
              "      <td>when do we think the courts will give a decisi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3206201</th>\n",
              "      <td>can you not buy xrp on coinbase? where can i buy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3206202</th>\n",
              "      <td>there is a rumor going around that the lawsuit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3206203 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      text\n",
              "0        **user report** :--:--:--:-- **total submissio...\n",
              "1        purchase but no positions? dont lie, you paper...\n",
              "2        post the fucking million with today’s date the...\n",
              "3                           congratulations! and fuck you!\n",
              "4        now use that money to make a time machine to b...\n",
              "...                                                    ...\n",
              "3206198  when is coinbase giving us our flare drops? it...\n",
              "3206199  what is time for open and close on a chart? it...\n",
              "3206200  when do we think the courts will give a decisi...\n",
              "3206201   can you not buy xrp on coinbase? where can i buy\n",
              "3206202  there is a rumor going around that the lawsuit...\n",
              "\n",
              "[3206203 rows x 1 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gptcrypto = pd.read_parquet('/Users/shaanp/projects/testing/datasets/gptcrpyot-dataset.parquet')\n",
        "gptcrypto.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "0rGgSHzAzERr",
        "outputId": "4a7f9470-b3d2-48b8-86f4-150e65433825"
      },
      "outputs": [],
      "source": [
        "from autotrain.params import LLMTrainingParams\n",
        "from autotrain.project import AutoTrainProject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "diBQ_u03zERr"
      },
      "outputs": [],
      "source": [
        "HF_USERNAME = \"Episte\"\n",
        "HF_TOKEN = \"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\" # get it from https://huggingface.co/settings/token\n",
        "# It is recommended to use secrets or environment variables to store your HF_TOKEN\n",
        "# your token is required if push_to_hub is set to True or if you are accessing a gated model/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Usage:   \n",
            "  /Users/shaanp/projects/testing/venv/bin/python -m pip <command> [options]\n",
            "\n",
            "no such option: --upgrade\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip --upgrade torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "dcqeO6DHzERs"
      },
      "outputs": [],
      "source": [
        "params = LLMTrainingParams(\n",
        "    model=\"Qwen/Qwen2.5-7B-Instruct\",\n",
        "    project_name=\"autotrainqwen\",\n",
        "    data_path=\"cogneolabs/Cogneo-Crypto-Sentiment\",\n",
        "    train_split=\"train\",\n",
        "    text_column=\"description\",  # Changed from 'text' to 'description'\n",
        "    trainer=\"default\",\n",
        "    epochs=1,\n",
        "    batch_size=2,\n",
        "    lr=3e-5,\n",
        "    warmup_ratio=0.1,\n",
        "    gradient_accumulation=4,\n",
        "    optimizer=\"adamw_torch\",\n",
        "    scheduler=\"linear\",\n",
        "    weight_decay=0.0,\n",
        "    max_grad_norm=1.0,\n",
        "    seed=42,\n",
        "    quantization=\"int4\",\n",
        "    target_modules=\"all-linear\",\n",
        "    block_size=1024,\n",
        "    model_max_length=2048,\n",
        "    padding=\"right\",\n",
        "    add_eos_token=True,\n",
        "    # Optional: if you want to combine columns, you can process them beforehand\n",
        "    # text_column=\"description,title\",  # This would combine both columns\n",
        "    log=\"none\",\n",
        "    peft=False,  # Set to False as in the current config\n",
        "    merge_adapter=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go0icAulzERs"
      },
      "source": [
        "If your dataset is in CSV / JSONL format (JSONL is most preferred) and is stored locally, make the following changes to `params`:\n",
        "\n",
        "```python\n",
        "params = LLMTrainingParams(\n",
        "    data_path=\"/Users/shaanp/projects/testing/0000.csv\", # this is the path to folder where train.jsonl/train.csv is located\n",
        "    text_column=\"text\", # this is the column name in the CSV/JSONL file which contains the text\n",
        "    train_split = \"0000\" # this is the filename without extension\n",
        "    .\n",
        "    .\n",
        "    .\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4aOpGdA6zERs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-02-06 17:42:46\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-02-06 17:42:46\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m514\u001b[0m - \u001b[1m['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'bf16', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrain-llama32-1b-finetune/training_params.json', '--mixed_precision', 'bf16', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrain-llama32-1b-finetune/training_params.json', '--mixed_precision', 'bf16', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-02-06 17:42:46\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m515\u001b[0m - \u001b[1m{'model': 'Qwen/Qwen2.5-7B-Instruct', 'project_name': 'autotrainqwen', 'data_path': 'cogneolabs/Cogneo-Crypto-Sentiment', 'train_split': 'train', 'valid_split': None, 'add_eos_token': True, 'block_size': 1024, 'model_max_length': 2048, 'padding': 'right', 'trainer': 'default', 'use_flash_attention_2': False, 'log': 'none', 'disable_gradient_checkpointing': False, 'logging_steps': -1, 'eval_strategy': 'epoch', 'save_total_limit': 1, 'auto_find_batch_size': False, 'mixed_precision': None, 'lr': 3e-05, 'epochs': 1, 'batch_size': 2, 'warmup_ratio': 0.1, 'gradient_accumulation': 4, 'optimizer': 'adamw_torch', 'scheduler': 'linear', 'weight_decay': 0.0, 'max_grad_norm': 1.0, 'seed': 42, 'chat_template': None, 'quantization': 'int4', 'target_modules': 'all-linear', 'merge_adapter': False, 'peft': False, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.05, 'model_ref': None, 'dpo_beta': 0.1, 'max_prompt_length': 128, 'max_completion_length': None, 'prompt_text_column': None, 'text_column': 'description', 'rejected_text_column': None, 'push_to_hub': False, 'username': None, 'token': None, 'unsloth': False, 'distributed_backend': None}\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/Users/shaanp/projects/testing/venv/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/Users/shaanp/projects/testing/venv/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/Users/shaanp/projects/testing/venv/lib/python3.12/site-packages/accelerate/commands/launch.py\", line 1146, in launch_command\n",
            "    args, defaults, mp_from_config_flag = _validate_launch_command(args)\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/shaanp/projects/testing/venv/lib/python3.12/site-packages/accelerate/commands/launch.py\", line 1066, in _validate_launch_command\n",
            "    raise ValueError(\"bf16 mixed precision requires PyTorch >= 1.10 and a supported device.\")\n",
            "ValueError: bf16 mixed precision requires PyTorch >= 1.10 and a supported device.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "42095"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# this will train the model locally\n",
        "project = AutoTrainProject(\n",
        "    params=params,\n",
        "    backend=\"local\",\n",
        "    process=True\n",
        ")\n",
        "project.create()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
