{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJGlmBQSzERq"
      },
      "source": [
        "# LLM Finetuning using AutoTrain\n",
        "\n",
        "In this notebook, we will finetune a Qwen/Qwen2.5-7b-instruct model using AutoTrain Advanced.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                              description         sentiment  \\\n",
              "0          What an exciting 5% range on $BTC all weekend   Bullish (77.9%)   \n",
              "1      $ETH - Nice bounce as expected, longs in profi...  Bullish (99.39%)   \n",
              "2      #Bitcoin - OBV has been in an uptrend since Ja...  Bullish (62.28%)   \n",
              "3                       $SXP we can come back 0.30 early           Bullish   \n",
              "4      $BTC\\n\\nThis does not look healthy...nasdaq al...  Bearish (78.02%)   \n",
              "...                                                  ...               ...   \n",
              "43022  #Bitcoin - Loving the strength. Able to share ...  Bullish (79.89%)   \n",
              "43023  $turbo $turbo short the CMP around 0.00065$ \\n...           Neutral   \n",
              "43024  #Bitcoin / $BTC\\n\\nLooking for this move to co...           Neutral   \n",
              "43025  Orange coin is about to breakout from a 600 da...           Bullish   \n",
              "43026  Yes, next entry 0.52\\nThen home ð¡\\n#ftm $ft...           Bullish   \n",
              "\n",
              "                                          title  \n",
              "0               CryptoGodJohn tweeted about BTC  \n",
              "1                IncomeSharks tweeted about ETH  \n",
              "2                    IncomeSharks tweeted about  \n",
              "3                     eliz883 tweeted about SXP  \n",
              "4                    ShardiB2 tweeted about BTC  \n",
              "...                                         ...  \n",
              "43022  IncomeSharks ð IncomeSharks about ETH  \n",
              "43023     Prof.Noan.Ai ðµ tweeted about TURBO  \n",
              "43024             CryptoKaleo tweeted about BTC  \n",
              "43025          JJcycles ð JJcycles about BTC  \n",
              "43026         CryptoNoan ð K_NON_9 about FTM  \n",
              "\n",
              "[43027 rows x 3 columns]>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('//Users/shaanp/projects/testing/datasets/sentiment.csv')\n",
        "df.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>**user report** :--:--:--:-- **total submissio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>purchase but no positions? dont lie, you paper...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>post the fucking million with today’s date the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>congratulations! and fuck you!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>now use that money to make a time machine to b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  **user report** :--:--:--:-- **total submissio...\n",
              "1  purchase but no positions? dont lie, you paper...\n",
              "2  post the fucking million with today’s date the...\n",
              "3                     congratulations! and fuck you!\n",
              "4  now use that money to make a time machine to b..."
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert = pd.read_parquet('/Users/shaanp/projects/testing/datasets/cryptobert-dataset.parquet')\n",
        "bert.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>**user report** :--:--:--:-- **total submissio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>purchase but no positions? dont lie, you paper...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>post the fucking million with today’s date the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>congratulations! and fuck you!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>now use that money to make a time machine to b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3206198</th>\n",
              "      <td>when is coinbase giving us our flare drops? it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3206199</th>\n",
              "      <td>what is time for open and close on a chart? it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3206200</th>\n",
              "      <td>when do we think the courts will give a decisi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3206201</th>\n",
              "      <td>can you not buy xrp on coinbase? where can i buy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3206202</th>\n",
              "      <td>there is a rumor going around that the lawsuit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3206203 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      text\n",
              "0        **user report** :--:--:--:-- **total submissio...\n",
              "1        purchase but no positions? dont lie, you paper...\n",
              "2        post the fucking million with today’s date the...\n",
              "3                           congratulations! and fuck you!\n",
              "4        now use that money to make a time machine to b...\n",
              "...                                                    ...\n",
              "3206198  when is coinbase giving us our flare drops? it...\n",
              "3206199  what is time for open and close on a chart? it...\n",
              "3206200  when do we think the courts will give a decisi...\n",
              "3206201   can you not buy xrp on coinbase? where can i buy\n",
              "3206202  there is a rumor going around that the lawsuit...\n",
              "\n",
              "[3206203 rows x 1 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gptcrypto = pd.read_parquet('/Users/shaanp/projects/testing/datasets/gptcrpyot-dataset.parquet')\n",
        "gptcrypto.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "0rGgSHzAzERr",
        "outputId": "4a7f9470-b3d2-48b8-86f4-150e65433825"
      },
      "outputs": [],
      "source": [
        "from autotrain.params import LLMTrainingParams\n",
        "from autotrain.project import AutoTrainProject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "diBQ_u03zERr"
      },
      "outputs": [],
      "source": [
        "HF_USERNAME = \"Episte\"\n",
        "HF_TOKEN = \"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\" # get it from https://huggingface.co/settings/token\n",
        "# It is recommended to use secrets or environment variables to store your HF_TOKEN\n",
        "# your token is required if push_to_hub is set to True or if you are accessing a gated model/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Usage:   \n",
            "  /Users/shaanp/projects/testing/venv/bin/python -m pip <command> [options]\n",
            "\n",
            "no such option: --upgrade\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip --upgrade torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "dcqeO6DHzERs"
      },
      "outputs": [],
      "source": [
        "params = LLMTrainingParams(\n",
        "    model=\"Qwen/Qwen2.5-7B-Instruct\",\n",
        "    project_name=\"autotrainqwen\",\n",
        "    data_path=\"cogneolabs/Cogneo-Crypto-Sentiment\",\n",
        "    train_split=\"train\",\n",
        "    text_column=\"description\",  # Changed from 'text' to 'description'\n",
        "    trainer=\"default\",\n",
        "    epochs=1,\n",
        "    batch_size=2,\n",
        "    lr=3e-5,\n",
        "    warmup_ratio=0.1,\n",
        "    gradient_accumulation=4,\n",
        "    optimizer=\"adamw_torch\",\n",
        "    scheduler=\"linear\",\n",
        "    weight_decay=0.0,\n",
        "    max_grad_norm=1.0,\n",
        "    seed=42,\n",
        "    quantization=\"int4\",\n",
        "    target_modules=\"all-linear\",\n",
        "    block_size=1024,\n",
        "    model_max_length=2048,\n",
        "    padding=\"right\",\n",
        "    add_eos_token=True,\n",
        "    # Optional: if you want to combine columns, you can process them beforehand\n",
        "    # text_column=\"description,title\",  # This would combine both columns\n",
        "    log=\"none\",\n",
        "    peft=False,  # Set to False as in the current config\n",
        "    merge_adapter=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go0icAulzERs"
      },
      "source": [
        "If your dataset is in CSV / JSONL format (JSONL is most preferred) and is stored locally, make the following changes to `params`:\n",
        "\n",
        "```python\n",
        "params = LLMTrainingParams(\n",
        "    data_path=\"/Users/shaanp/projects/testing/0000.csv\", # this is the path to folder where train.jsonl/train.csv is located\n",
        "    text_column=\"text\", # this is the column name in the CSV/JSONL file which contains the text\n",
        "    train_split = \"0000\" # this is the filename without extension\n",
        "    .\n",
        "    .\n",
        "    .\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4aOpGdA6zERs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-02-06 17:42:46\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-02-06 17:42:46\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m514\u001b[0m - \u001b[1m['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'bf16', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrain-llama32-1b-finetune/training_params.json', '--mixed_precision', 'bf16', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrain-llama32-1b-finetune/training_params.json', '--mixed_precision', 'bf16', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'autotrainqwen/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-02-06 17:42:46\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m515\u001b[0m - \u001b[1m{'model': 'Qwen/Qwen2.5-7B-Instruct', 'project_name': 'autotrainqwen', 'data_path': 'cogneolabs/Cogneo-Crypto-Sentiment', 'train_split': 'train', 'valid_split': None, 'add_eos_token': True, 'block_size': 1024, 'model_max_length': 2048, 'padding': 'right', 'trainer': 'default', 'use_flash_attention_2': False, 'log': 'none', 'disable_gradient_checkpointing': False, 'logging_steps': -1, 'eval_strategy': 'epoch', 'save_total_limit': 1, 'auto_find_batch_size': False, 'mixed_precision': None, 'lr': 3e-05, 'epochs': 1, 'batch_size': 2, 'warmup_ratio': 0.1, 'gradient_accumulation': 4, 'optimizer': 'adamw_torch', 'scheduler': 'linear', 'weight_decay': 0.0, 'max_grad_norm': 1.0, 'seed': 42, 'chat_template': None, 'quantization': 'int4', 'target_modules': 'all-linear', 'merge_adapter': False, 'peft': False, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.05, 'model_ref': None, 'dpo_beta': 0.1, 'max_prompt_length': 128, 'max_completion_length': None, 'prompt_text_column': None, 'text_column': 'description', 'rejected_text_column': None, 'push_to_hub': False, 'username': None, 'token': None, 'unsloth': False, 'distributed_backend': None}\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/Users/shaanp/projects/testing/venv/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/Users/shaanp/projects/testing/venv/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/Users/shaanp/projects/testing/venv/lib/python3.12/site-packages/accelerate/commands/launch.py\", line 1146, in launch_command\n",
            "    args, defaults, mp_from_config_flag = _validate_launch_command(args)\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/shaanp/projects/testing/venv/lib/python3.12/site-packages/accelerate/commands/launch.py\", line 1066, in _validate_launch_command\n",
            "    raise ValueError(\"bf16 mixed precision requires PyTorch >= 1.10 and a supported device.\")\n",
            "ValueError: bf16 mixed precision requires PyTorch >= 1.10 and a supported device.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "42095"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# this will train the model locally\n",
        "project = AutoTrainProject(\n",
        "    params=params,\n",
        "    backend=\"local\",\n",
        "    process=True\n",
        ")\n",
        "project.create()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
